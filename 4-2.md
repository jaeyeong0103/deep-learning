 K-fold Cross Validation (교차 검증)
데이터가 부족할 때 검증 데이터를 더 효과적으로 사용 가능
만약 검증 데이터가 어느 한 데이터에 편향된 경우 그 데이터에 편향된 모델이 만들어 질 수가 있음으로  K-fold Cross Validation 방식으로
검증 데이터 쌍을 만든다 서로 다른 훈련/검증 데이터 조합을 만들고 각 조합에 대한 loss 평균을 낸다 val loss 기준으로 하이퍼파라미터를 선정하면
편향 문제를 줄일 수 있다 그러나 이 방식은 검증 데이터 쌍 개수만큼 걸리는 시간이 배가 된다
가장 val loss가 낮은 하이퍼파라미터 세트를 선택하게 된다
