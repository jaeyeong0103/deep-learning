다중 분류
One-Hot Encording : [1, 0, 0] 하나의 값만 1이고 나머지는 0인벡터로 표현, 각 클래스 간 우선순위를 두지 않음 클래스 개수만큼의 노드 수가 필요함
3X100X100 인 경우 출력 노드가 3개임으로 웨이트의 개수는 9만개이고 바이어스는 3개이기에 그래디언트 크기는 90003이다 이 모델은 출력 노드 수를 늘려서 각 노드가 각 객체 판단을 담당하게 된다
만약 출력이 [0,100,0] [-1,1,-1] 이라면 [0,1,0] 과 동일취급을 하게 되는데 이런 일을 해결하기 위해중 분류
One-Hot Encording : [1, 0, 0] 하나의 값만 1이고 나머지는 0인벡터로 표현, 각 클래스 간 우선순위를 두지 않음 클래스 개수만큼의 노드 수가 필요함
3X100X100 인 경우 출력 노드가 3개임으로 웨이트의 개수는 9만개이고 바이어스는 3개이기에 그래디언트 크기는 90003이다 이 모델은 출력 노드 수를 늘려서 각 노드가 각 객체 판단을 담당하게 된다
만약 출력이 [0,100,0] [-1,1,-1] 이라면 [0,1,0] 과 동일취급을 하게 되는데 이런 일을 해결하기 위해 각 출력 값을 양수이면서 그 합이 1이 나오지 않도록 제한을 둔다 이를 Softmax라 한다
Softmax : 여러 개의 실수값을 입력받아 각 출력의 값이 양수이면서 그 합이 1이 되도록 변환하는 함수이다 (확률 분포로 해석 가능)
각 노드에 sigmoid 함수를 적용하는 방법도 고려해 볼 수 있지만 One-Hot Encording 레이블의 특성을 활용하지 못해 Softmax보다 성능이 떨어진다
다중 레이블 분류(Multi-label Classification) : 하나의 이미지에 여러 클래스가 동시 존재 이런 경우 레이블 합이 1이 아니므로 Softmax를 사용하기에 적절하지 않다
다중 분류애소 레이블이 카테고리 분포를 따른다고 가정하고 NLL을 구하면 이때 얻은 loss 는 Cross-Entropy Loss 이다
카테고리 분포는 멀티누이 분포 라고 불림. 카테고리 분포는 세가지 이상 결과를 다루고 랜덤 벡터에 대한 확률을 다룬다
항상 엔트로피는 CE보다 작거나 같다 입력이 들어가면 대응되는 출력이 나오게끔 분포 차이를 나타내는 Cross-Entropy를 loss 로 삼은 것이다 이는 Multinomial Logistic Regression 이라 불리기도 한다
Softmax 회귀는 Logit들을 선형 회귀를 통해 구하는 것으로 해석할 수 있다 (모델에 Multinomial Logistic Regression를 적용하지 않음)
Softmax는 신경망 일부가 아니라loss를 얻기 위해 Logit들을 확률분포를 변환하고 Cross-Entropy Loss 계산하기 위해 사용되는 함수 Softmax 회귀는 선형 회귀를 통해 Logit들을 예측하고 이를 확률 분포로 변환하여 해결하는 방법이다





