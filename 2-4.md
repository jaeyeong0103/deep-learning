웨이트와 바이어스를 바꿔가며 구하는 것은 시간적으로 한계가 있음
Gradient Descent : 경사 하강법 
                   웨이터와 바이어스 값을 임의로 잡는다.
                   gradient 함수는 항상 기을기가 가장 가파른 방향으로 이동하기에, loss 그래프의 gradient 값을 구한 다음
                   반대 방향으로 이동하여 최적의 웨이트와 바이어스 값을 구한다. 
                   Learnig rate : gradient 함수의 반대 방향으로 이동할 때 보폭을 조절하는 역할
                                  모델의 복잡도와 데이터의 특성에 따라 조절함
          문제점 : 계산 속도가 느리다
                   local minimum에 빠진다 loss 함수가 여러 개의 아래로 볼록한 형태를 가질 때 생김
                   출발지점과 가장 가까운 로컬 미니멈으로 갈 수 밖에 없기에 충분한 탐색이 이루어 질 수가 없다
                   global minimum 뒤 위치에서 시작하면 안일어남
                   
                   
                    
